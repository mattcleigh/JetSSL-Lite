model_summary:
  _target_: lightning.pytorch.callbacks.RichModelSummary
  max_depth: 2

lr_monitor:
  _target_: lightning.pytorch.callbacks.LearningRateMonitor
  logging_interval: step

backbone_finetune:
  _target_: src.callbacks.finetuning.CatchupToLR
  unfreeze_at_step: -1 # Never unfreeze
  catchup_steps: 1000

best_checkpoint:
  _target_: lightning.pytorch.callbacks.ModelCheckpoint
  dirpath: ${full_path}/checkpoints
  filename: best
  monitor: valid/total_loss
  mode: min
  save_weights_only: True
  auto_insert_metric_name: False
  enable_version_counter: False
